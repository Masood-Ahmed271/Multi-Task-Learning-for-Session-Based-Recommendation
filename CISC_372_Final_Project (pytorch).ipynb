{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-p7klkl9VM1m"
      },
      "source": [
        "# CISC 372 Final Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "appig2XkVSpP"
      },
      "source": [
        "Student name: Liangjin LIN (20164732), Cheuk Him CHAU (20378374), Masood Ahmed (20379714), \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--rkq2RcXqAM"
      },
      "source": [
        "The three research questions are:\n",
        "1. Is there a gap between the efficiency of using a single Session-Based Recommendation (SBR) algorithm and Session-Based Recommendation (SBR) along with multi-task learning?\n",
        "2. How sensitive are the parameters to these algorithms?\n",
        "3. Is there a gap between the efficiency of the algorithms\n",
        "mentioned involving cold-start users?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysg1zGeCC_uG"
      },
      "source": [
        "Findings on data:\n",
        "1. \"QK-video\", \"QK-article\", \"QB-video\", \"QB-article\" are raw datasets.\n",
        "2. There is a dataset called \"sbr_data_1M\", which is used for SBR in the original paper. We can use this dataset for our project."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9u4wnPsWVX7Z"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FDtLo8sPVCb1"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries\n",
        "# from google.colab import drive\n",
        "import pandas as pd\n",
        "#import tensorflow as tf\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka_yAl5GVgwU",
        "outputId": "d46725c2-be47-49bb-b1f1-50eb3e8e811b"
      },
      "outputs": [],
      "source": [
        "# Do not use this, upload the data here is very slow\n",
        "\n",
        "# upload file from local system\n",
        "# from google.colab import files\n",
        "# uploades = files.upload()\n",
        "\n",
        "# Use this instead, the dataset is uploaded to the shared google drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM_mIuQZ6JH-",
        "outputId": "fc44d9c4-e16f-4680-ad5b-9fdbc2f3bbdf"
      },
      "outputs": [],
      "source": [
        "# !ls \"./gdrive/MyDrive/CISC351 Advance Data Analytics/Dataset\"\n",
        "# !ls \"./gdrive/MyDrive/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLLbyZodUtRw",
        "outputId": "8f93dcca-4b3f-479b-d151-7b122dc7521f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\wilso\\anaconda3\\envs\\cisc351\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3186: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>click</th>\n",
              "      <th>follow</th>\n",
              "      <th>like</th>\n",
              "      <th>share</th>\n",
              "      <th>video_category</th>\n",
              "      <th>watching_times</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>80936</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>781</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  item_id  click  follow  like  share video_category  \\\n",
              "0        1        1      1       0     0      0              1   \n",
              "1        1        2      1       0     0      0              1   \n",
              "2        1        3      1       0     0      0              0   \n",
              "3        1    80936      1       0     0      0              1   \n",
              "4        1      781      1       0     0      0              1   \n",
              "\n",
              "   watching_times  gender  age  \n",
              "0               1       1    4  \n",
              "1               1       1    4  \n",
              "2               1       1    4  \n",
              "3               1       1    4  \n",
              "4               1       1    4  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_path = \"./Tenrec/sbr_data_1M.csv\"\n",
        "sbr_data = pd.read_csv(data_path)\n",
        "sbr_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oIPawk-47FGy"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "user_id\n",
              "1       71\n",
              "2       15\n",
              "3       37\n",
              "4       27\n",
              "5       53\n",
              "      ... \n",
              "557    160\n",
              "558     59\n",
              "559     91\n",
              "560     19\n",
              "561      1\n",
              "Name: item_id, Length: 561, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = sbr_data.loc[:25599]\n",
        "df.groupby(\"user_id\")[\"item_id\"].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjK9vdXWr6zu",
        "outputId": "74559bc0-a67e-429b-90db-2941530cc05c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-- Starting @ 2023-04-11 12:31:32.955105s\n",
            "-- Reading data @ 2023-04-11 12:31:34.569106s\n",
            "9414\n"
          ]
        }
      ],
      "source": [
        "# Preprocess the data\n",
        "\n",
        "import argparse\n",
        "import time\n",
        "import csv\n",
        "import pickle\n",
        "import operator\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# Read the data\n",
        "print(\"-- Starting @ %ss\" % datetime.datetime.now())\n",
        "sess_clicks = {}\n",
        "\n",
        "ctr = 0\n",
        "\n",
        "for _, data in df.iterrows():\n",
        "    sessid = data['user_id']\n",
        "\n",
        "    item = data[\"item_id\"]\n",
        "\n",
        "    if sessid in sess_clicks:\n",
        "        sess_clicks[sessid] += [item]\n",
        "    else:\n",
        "        sess_clicks[sessid] = [item]\n",
        "    ctr += 1\n",
        "\n",
        "print(\"-- Reading data @ %ss\" % datetime.datetime.now())\n",
        "\n",
        "# Filter out sessions with length less than 10\n",
        "for s in list(sess_clicks):\n",
        "    if len(sess_clicks[s]) < 10:\n",
        "        del sess_clicks[s]\n",
        "\n",
        "# Set the max session length to 30\n",
        "for key, ls in sess_clicks.items():\n",
        "  if len(ls) > 30:\n",
        "    sess_clicks[key] = ls[-30:]\n",
        "\n",
        "# Transform users' ids and interactions into a 2d list\n",
        "user_interactions = [ls for _, ls in sess_clicks.items()]\n",
        "user_ids = [id for id, _ in sess_clicks.items()]\n",
        "\n",
        "# splitting the data into training and testing sets\n",
        "n_10pct = len(user_interactions) // 10\n",
        "test_sess = user_interactions[:n_10pct]\n",
        "train_sess = user_interactions[n_10pct+1:]\n",
        "test_ids = user_ids[:n_10pct]\n",
        "test_ids = user_ids[n_10pct+1:]\n",
        "\n",
        "# Count the number of unique items in training set\n",
        "items = set()\n",
        "ctr = 1\n",
        "for seq in train_sess:\n",
        "    for s in seq:\n",
        "        if s not in items:\n",
        "            items.add(s)\n",
        "            ctr +=1\n",
        "print(ctr)\n",
        "\n",
        "# If we need to split the validation set out by hand\n",
        "# test_sess = user_interactions[:n_10pct]\n",
        "# valid_sess = user_interactions[n_10pct+1:2*n_10pct]\n",
        "# train_sess = user_interactions[2*n_10pct+1:]\n",
        "# test_ids = user_ids[:n_10pct]\n",
        "# valid_ids = user_ids[n_10pct+1:2*n_10pct]\n",
        "# test_ids = user_ids[n_10pct+1:]\n",
        "\n",
        "def process_seqs(in_seqs):\n",
        "    out_seqs = []\n",
        "    labs = []\n",
        "    for seq in in_seqs:\n",
        "        for i in range(1, len(seq)):\n",
        "            tar = seq[-i]\n",
        "            labs += [tar]\n",
        "            out_seqs += [seq[:-i]]\n",
        "    return out_seqs, labs\n",
        "\n",
        "\n",
        "train_seqs, train_labs = process_seqs(train_sess)\n",
        "test_seqs, test_labs = process_seqs(test_sess)\n",
        "train = (train_seqs, train_labs)\n",
        "test = (test_seqs, test_labs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFhmx4h3yy2I"
      },
      "source": [
        "SR-GNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exIBFVfPy0U1",
        "outputId": "4f747736-35d4-4bc6-bcda-8ec6ba7cf0b6"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python36\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on July, 2018\n",
        "@author: Tangrizzly\n",
        "\"\"\"\n",
        "\n",
        "import datetime\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import Module, Parameter\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class GNN(Module):\n",
        "    def __init__(self, hidden_size, step=1):\n",
        "        super(GNN, self).__init__()\n",
        "        self.step = step\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = hidden_size * 2\n",
        "        self.gate_size = 3 * hidden_size\n",
        "        self.w_ih = Parameter(torch.Tensor(self.gate_size, self.input_size))\n",
        "        self.w_hh = Parameter(torch.Tensor(self.gate_size, self.hidden_size))\n",
        "        self.b_ih = Parameter(torch.Tensor(self.gate_size))\n",
        "        self.b_hh = Parameter(torch.Tensor(self.gate_size))\n",
        "        self.b_iah = Parameter(torch.Tensor(self.hidden_size))\n",
        "        self.b_oah = Parameter(torch.Tensor(self.hidden_size))\n",
        "\n",
        "        self.linear_edge_in = nn.Linear(self.hidden_size, self.hidden_size, bias=True)\n",
        "        self.linear_edge_out = nn.Linear(self.hidden_size, self.hidden_size, bias=True)\n",
        "        self.linear_edge_f = nn.Linear(self.hidden_size, self.hidden_size, bias=True)\n",
        "\n",
        "    def GNNCell(self, A, hidden):\n",
        "        input_in = torch.matmul(A[:, :, :A.shape[1]], self.linear_edge_in(hidden)) + self.b_iah\n",
        "        input_out = torch.matmul(A[:, :, A.shape[1]: 2 * A.shape[1]], self.linear_edge_out(hidden)) + self.b_oah\n",
        "        inputs = torch.cat([input_in, input_out], 2)\n",
        "        gi = F.linear(inputs, self.w_ih, self.b_ih)\n",
        "        gh = F.linear(hidden, self.w_hh, self.b_hh)\n",
        "        i_r, i_i, i_n = gi.chunk(3, 2)\n",
        "        h_r, h_i, h_n = gh.chunk(3, 2)\n",
        "        resetgate = torch.sigmoid(i_r + h_r)\n",
        "        inputgate = torch.sigmoid(i_i + h_i)\n",
        "        newgate = torch.tanh(i_n + resetgate * h_n)\n",
        "        hy = newgate + inputgate * (hidden - newgate)\n",
        "        return hy\n",
        "\n",
        "    def forward(self, A, hidden):\n",
        "        for i in range(self.step):\n",
        "            hidden = self.GNNCell(A, hidden)\n",
        "        return hidden\n",
        "\n",
        "\n",
        "class SessionGraph(Module):\n",
        "    def __init__(self, opt, n_node):\n",
        "        super(SessionGraph, self).__init__()\n",
        "        self.hidden_size = opt[\"hiddenSize\"]\n",
        "        self.n_node = n_node\n",
        "        self.batch_size = opt[\"batchSize\"]\n",
        "        self.nonhybrid = opt[\"nonhybrid\"]\n",
        "        self.embedding = nn.Embedding(self.n_node, self.hidden_size)\n",
        "        self.gnn = GNN(self.hidden_size, step=opt[\"step\"])\n",
        "        self.linear_one = nn.Linear(self.hidden_size, self.hidden_size, bias=True)\n",
        "        self.linear_two = nn.Linear(self.hidden_size, self.hidden_size, bias=True)\n",
        "        self.linear_three = nn.Linear(self.hidden_size, 1, bias=False)\n",
        "        self.linear_transform = nn.Linear(self.hidden_size * 2, self.hidden_size, bias=True)\n",
        "        self.loss_function = nn.CrossEntropyLoss()\n",
        "        self.optimizer = torch.optim.Adam(self.parameters(), lr=opt[\"lr\"], weight_decay=opt[\"l2\"])\n",
        "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=opt[\"lr_dc_step\"], gamma=opt[\"lr_dc\"])\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for weight in self.parameters():\n",
        "            weight.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def compute_scores(self, hidden, mask):\n",
        "        ht = hidden[torch.arange(mask.shape[0]).long(), torch.sum(mask, 1) - 1]  # batch_size x latent_size\n",
        "        q1 = self.linear_one(ht).view(ht.shape[0], 1, ht.shape[1])  # batch_size x 1 x latent_size\n",
        "        q2 = self.linear_two(hidden)  # batch_size x seq_length x latent_size\n",
        "        alpha = self.linear_three(torch.sigmoid(q1 + q2))\n",
        "        a = torch.sum(alpha * hidden * mask.view(mask.shape[0], -1, 1).float(), 1)\n",
        "        if not self.nonhybrid:\n",
        "            a = self.linear_transform(torch.cat([a, ht], 1))\n",
        "        b = self.embedding.weight[1:]  # n_nodes x latent_size\n",
        "        scores = torch.matmul(a, b.transpose(1, 0))\n",
        "        return scores\n",
        "\n",
        "    def forward(self, inputs, A):\n",
        "        hidden = self.embedding(inputs)\n",
        "        hidden = self.gnn(A, hidden)\n",
        "        return hidden\n",
        "\n",
        "\n",
        "def trans_to_cuda(variable):\n",
        "    if torch.cuda.is_available():\n",
        "        return variable.cuda()\n",
        "    else:\n",
        "        return variable\n",
        "\n",
        "\n",
        "def trans_to_cpu(variable):\n",
        "    if torch.cuda.is_available():\n",
        "        return variable.cpu()\n",
        "    else:\n",
        "        return variable\n",
        "\n",
        "\n",
        "def forward(model, i, data):\n",
        "    alias_inputs, A, items, mask, targets = data.get_slice(i)\n",
        "    alias_inputs = trans_to_cuda(torch.Tensor(alias_inputs).long())\n",
        "    items = trans_to_cuda(torch.Tensor(items).long())\n",
        "    A = trans_to_cuda(torch.Tensor(A).float())\n",
        "    mask = trans_to_cuda(torch.Tensor(mask).long())\n",
        "    print(items.size())\n",
        "    print(A.size())\n",
        "    hidden = model(items, A)\n",
        "    get = lambda i: hidden[i][alias_inputs[i]]\n",
        "    seq_hidden = torch.stack([get(i) for i in torch.arange(len(alias_inputs)).long()])\n",
        "    return targets, model.compute_scores(seq_hidden, mask)\n",
        "\n",
        "\n",
        "def train_test(model, train_data, test_data):\n",
        "    model.scheduler.step()\n",
        "    print('start training: ', datetime.datetime.now())\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    slices = train_data.generate_batch(model.batch_size)\n",
        "    for i, j in zip(slices, np.arange(len(slices))):\n",
        "        model.optimizer.zero_grad()\n",
        "        targets, scores = forward(model, i, train_data)\n",
        "        targets = trans_to_cuda(torch.Tensor(targets).long())\n",
        "        loss = model.loss_function(scores, targets - 1)\n",
        "        loss.backward()\n",
        "        model.optimizer.step()\n",
        "        total_loss += loss\n",
        "        if j % int(len(slices) / 5 + 1) == 0:\n",
        "            print('[%d/%d] Loss: %.4f' % (j, len(slices), loss.item()))\n",
        "    print('\\tLoss:\\t%.3f' % total_loss)\n",
        "\n",
        "    print('start predicting: ', datetime.datetime.now())\n",
        "    model.eval()\n",
        "    hit, mrr = [], []\n",
        "    slices = test_data.generate_batch(model.batch_size)\n",
        "    for i in slices:\n",
        "        targets, scores = forward(model, i, test_data)\n",
        "        sub_scores = scores.topk(20)[1]\n",
        "        sub_scores = trans_to_cpu(sub_scores).detach().numpy()\n",
        "        for score, target, mask in zip(sub_scores, targets, test_data.mask):\n",
        "            hit.append(np.isin(target - 1, score))\n",
        "            if len(np.where(score == target - 1)[0]) == 0:\n",
        "                mrr.append(0)\n",
        "            else:\n",
        "                mrr.append(1 / (np.where(score == target - 1)[0][0] + 1))\n",
        "    hit = np.mean(hit) * 100\n",
        "    mrr = np.mean(mrr) * 100\n",
        "    return hit, mrr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3PwqK4ZxzBE_"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def build_graph(train_data):\n",
        "    graph = nx.DiGraph()\n",
        "    for seq in train_data:\n",
        "        for i in range(len(seq) - 1):\n",
        "            if graph.get_edge_data(seq[i], seq[i + 1]) is None:\n",
        "                weight = 1\n",
        "            else:\n",
        "                weight = graph.get_edge_data(seq[i], seq[i + 1])['weight'] + 1\n",
        "            graph.add_edge(seq[i], seq[i + 1], weight=weight)\n",
        "    for node in graph.nodes:\n",
        "        sum = 0\n",
        "        for j, i in graph.in_edges(node):\n",
        "            sum += graph.get_edge_data(j, i)['weight']\n",
        "        if sum != 0:\n",
        "            for j, i in graph.in_edges(i):\n",
        "                graph.add_edge(j, i, weight=graph.get_edge_data(j, i)['weight'] / sum)\n",
        "    return graph\n",
        "\n",
        "\n",
        "def data_masks(all_usr_pois, item_tail):\n",
        "    us_lens = [len(upois) for upois in all_usr_pois]\n",
        "    len_max = max(us_lens)\n",
        "    us_pois = [upois + item_tail * (len_max - le) for upois, le in zip(all_usr_pois, us_lens)]\n",
        "    us_msks = [[1] * le + [0] * (len_max - le) for le in us_lens]\n",
        "    return us_pois, us_msks, len_max\n",
        "\n",
        "\n",
        "def split_validation(train_set, valid_portion):\n",
        "    train_set_x, train_set_y = train_set\n",
        "    n_samples = len(train_set_x)\n",
        "    sidx = np.arange(n_samples, dtype='int32')\n",
        "    np.random.shuffle(sidx)\n",
        "    n_train = int(np.round(n_samples * (1. - valid_portion)))\n",
        "    valid_set_x = [train_set_x[s] for s in sidx[n_train:]]\n",
        "    valid_set_y = [train_set_y[s] for s in sidx[n_train:]]\n",
        "    train_set_x = [train_set_x[s] for s in sidx[:n_train]]\n",
        "    train_set_y = [train_set_y[s] for s in sidx[:n_train]]\n",
        "\n",
        "    return (train_set_x, train_set_y), (valid_set_x, valid_set_y)\n",
        "\n",
        "\n",
        "class Data():\n",
        "    def __init__(self, data, shuffle=False, graph=None):\n",
        "        inputs = data[0]\n",
        "        inputs, mask, len_max = data_masks(inputs, [0])\n",
        "        self.inputs = np.asarray(inputs)\n",
        "        self.mask = np.asarray(mask)\n",
        "        self.len_max = len_max\n",
        "        self.targets = np.asarray(data[1])\n",
        "        self.length = len(inputs)\n",
        "        self.shuffle = shuffle\n",
        "        self.graph = graph\n",
        "\n",
        "    def generate_batch(self, batch_size):\n",
        "        if self.shuffle:\n",
        "            shuffled_arg = np.arange(self.length)\n",
        "            np.random.shuffle(shuffled_arg)\n",
        "            self.inputs = self.inputs[shuffled_arg]\n",
        "            self.mask = self.mask[shuffled_arg]\n",
        "            self.targets = self.targets[shuffled_arg]\n",
        "        n_batch = int(self.length / batch_size)\n",
        "        if self.length % batch_size != 0:\n",
        "            n_batch += 1\n",
        "        slices = np.split(np.arange(n_batch * batch_size), n_batch)\n",
        "        slices[-1] = slices[-1][:(self.length - batch_size * (n_batch - 1))]\n",
        "        return slices\n",
        "\n",
        "    def get_slice(self, i):\n",
        "        inputs, mask, targets = self.inputs[i], self.mask[i], self.targets[i]\n",
        "        items, n_node, A, alias_inputs = [], [], [], []\n",
        "        for u_input in inputs:\n",
        "            n_node.append(len(np.unique(u_input)))\n",
        "        max_n_node = np.max(n_node)\n",
        "        for u_input in inputs:\n",
        "            node = np.unique(u_input)\n",
        "            items.append(node.tolist() + (max_n_node - len(node)) * [0])\n",
        "            u_A = np.zeros((max_n_node, max_n_node))\n",
        "            for i in np.arange(len(u_input) - 1):\n",
        "                if u_input[i + 1] == 0:\n",
        "                    break\n",
        "                u = np.where(node == u_input[i])[0][0]\n",
        "                v = np.where(node == u_input[i + 1])[0][0]\n",
        "                u_A[u][v] = 1\n",
        "            u_sum_in = np.sum(u_A, 0)\n",
        "            u_sum_in[np.where(u_sum_in == 0)] = 1\n",
        "            u_A_in = np.divide(u_A, u_sum_in)\n",
        "            u_sum_out = np.sum(u_A, 1)\n",
        "            u_sum_out[np.where(u_sum_out == 0)] = 1\n",
        "            u_A_out = np.divide(u_A.transpose(), u_sum_out)\n",
        "            u_A = np.concatenate([u_A_in, u_A_out]).transpose()\n",
        "            A.append(u_A)\n",
        "            alias_inputs.append([np.where(node == i)[0][0] for i in u_input])\n",
        "        return alias_inputs, A, items, mask, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pad 0 into those lists with length less than 30\n",
        "# for row in user_interactions:\n",
        "#     row += [0] * (30 - len(row))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ejFKBNNENAa1"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from collections import defaultdict\n",
        "\n",
        "# processedData = pd.DataFrame( dict([ (k, pd.Series(v)) for k,v in sess_clicks.items()]) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------\n",
            "epoch:  0\n",
            "start training:  2023-04-11 12:31:36.421835\n",
            "torch.Size([16, 28])\n",
            "torch.Size([16, 28, 56])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\wilso\\anaconda3\\envs\\cisc351\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "c:\\Users\\wilso\\anaconda3\\envs\\cisc351\\lib\\site-packages\\ipykernel_launcher.py:114: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23976\\2831013255.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-------------------------------------------------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mhit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmrr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhit\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mbest_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23976\\3981140869.py\u001b[0m in \u001b[0;36mtrain_test\u001b[1;34m(model, train_data, test_data)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrans_to_cuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23976\\3981140869.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, i, data)\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[0mget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0malias_inputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0mseq_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malias_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\wilso\\anaconda3\\envs\\cisc351\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23976\\3981140869.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, A)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\wilso\\anaconda3\\envs\\cisc351\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23976\\3981140869.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, A, hidden)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGNNCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23976\\3981140869.py\u001b[0m in \u001b[0;36mGNNCell\u001b[1;34m(self, A, hidden)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mGNNCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0minput_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_edge_in\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_iah\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0minput_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_edge_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_oah\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_out\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\wilso\\anaconda3\\envs\\cisc351\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\wilso\\anaconda3\\envs\\cisc351\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "\n",
        "import os\n",
        "import torch.backends.cudnn as cudnn\n",
        "cudnn.benchmark = False\n",
        "cudnn.deterministic = True\n",
        "torch.set_default_tensor_type(torch.DoubleTensor)\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = '1'\n",
        "\n",
        "opt = {\"batchSize\":16, \n",
        "\"hiddenSize\" : 256,\n",
        "\"epoch\" : 5,\n",
        "\"lr\" : 0.001,\n",
        "\"lr_dc\" : 0.1,\n",
        "\"lr_dc_step\" : 3,\n",
        "\"l2\" : 1e-5,\n",
        "\"step\" : 1,\n",
        "\"patience\" : 10,\n",
        "\"nonhybrid\" : \"store_true\",\n",
        "\"validation\" : \"store_true\",\n",
        "\"valid_portion\" : 0.1}\n",
        "n_node = 9414\n",
        "\n",
        "train_data = Data(train, shuffle=True)\n",
        "test_data = Data(test, shuffle=False)\n",
        "\n",
        "model = trans_to_cuda(SessionGraph(opt, n_node))\n",
        "\n",
        "start = time.time()\n",
        "best_result = [0, 0]\n",
        "best_epoch = [0, 0]\n",
        "bad_counter = 0\n",
        "for epoch in range(opt[\"epoch\"]):\n",
        "    print('-------------------------------------------------------')\n",
        "    print('epoch: ', epoch)\n",
        "    hit, mrr = train_test(model, train_data, test_data)\n",
        "    flag = 0\n",
        "    if hit >= best_result[0]:\n",
        "        best_result[0] = hit\n",
        "        best_epoch[0] = epoch\n",
        "        flag = 1\n",
        "    if mrr >= best_result[1]:\n",
        "        best_result[1] = mrr\n",
        "        best_epoch[1] = epoch\n",
        "        flag = 1\n",
        "    print('Best Result:')\n",
        "    print('\\tRecall@20:\\t%.4f\\tMMR@20:\\t%.4f\\tEpoch:\\t%d,\\t%d'% (best_result[0], best_result[1], best_epoch[0], best_epoch[1]))\n",
        "    bad_counter += 1 - flag\n",
        "    if bad_counter >= opt.patience:\n",
        "        break\n",
        "print('-------------------------------------------------------')\n",
        "end = time.time()\n",
        "print(\"Run time: %f s\" % (end - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(torch.cuda.max_memory_allocated())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select GPU device\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "# Get current memory usage\n",
        "print(torch.cuda.memory_allocated(device=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "MRfNbJxYq82D",
        "outputId": "d3d965c1-b69c-48a2-c910-b799a4c428f7"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "import numpy as np\n",
        "import pickle\n",
        "import argparse\n",
        "import datetime\n",
        "\n",
        "method = \"ggnn\"\n",
        "epoch = 5\n",
        "batchSize = 256\n",
        "hiddenSize = 256\n",
        "penalty = 0.00001\n",
        "learningRate = 0.001\n",
        "step = 1\n",
        "lr_dc = 0.1\n",
        "lr_dc_step = 3\n",
        "nonhybrid = 'store_true'\n",
        "n_node = 4000\n",
        "\n",
        "\n",
        "train_data = Data(train, sub_graph=True, method=method, shuffle=True)\n",
        "test_data = Data(test, sub_graph=True, method=method, shuffle=False)\n",
        "model = GGNN(hidden_size=hiddenSize, out_size=hiddenSize, batch_size=batchSize, n_node=n_node,\n",
        "                 lr=learningRate, l2=penalty,  step=step, decay=lr_dc_step * len(train_data.inputs) / batchSize, lr_dc=lr_dc,\n",
        "                 nonhybrid=nonhybrid)\n",
        "\n",
        "best_result = [0, 0]\n",
        "best_epoch = [0, 0]\n",
        "for epoch in range(epoch):\n",
        "    print('epoch: ', epoch, '===========================================')\n",
        "    slices = train_data.generate_batch(model.batch_size)\n",
        "    fetches = [model.opt, model.loss_train, model.global_step]\n",
        "    print('start training: ', datetime.datetime.now())\n",
        "    loss_ = []\n",
        "    for i, j in zip(slices, np.arange(len(slices))):\n",
        "        print(\"slices: \", slices)\n",
        "        print(i)\n",
        "        print(j)\n",
        "        adj_in, adj_out, alias, item, mask, targets = train_data.get_slice(i)\n",
        "        _, loss, _ = model.run(fetches, targets, item, adj_in, adj_out, alias,  mask)\n",
        "        loss_.append(loss)\n",
        "    loss = np.mean(loss_)\n",
        "    slices = test_data.generate_batch(model.batch_size)\n",
        "    print('start predicting: ', datetime.datetime.now())\n",
        "    hit, mrr, test_loss_ = [], [],[]\n",
        "    for i, j in zip(slices, np.arange(len(slices))):\n",
        "        adj_in, adj_out, alias, item, mask, targets = test_data.get_slice(i)\n",
        "        scores, test_loss = model.run([model.score_test, model.loss_test], targets, item, adj_in, adj_out, alias,  mask)\n",
        "        test_loss_.append(test_loss)\n",
        "        index = np.argsort(scores, 1)[:, -20:]\n",
        "        for score, target in zip(index, targets):\n",
        "            hit.append(np.isin(target - 1, score))\n",
        "            if len(np.where(score == target - 1)[0]) == 0:\n",
        "                mrr.append(0)\n",
        "            else:\n",
        "                mrr.append(1 / (20-np.where(score == target - 1)[0][0]))\n",
        "    hit = np.mean(hit)*100\n",
        "    mrr = np.mean(mrr)*100\n",
        "    test_loss = np.mean(test_loss_)\n",
        "    if hit >= best_result[0]:\n",
        "        best_result[0] = hit\n",
        "        best_epoch[0] = epoch\n",
        "    if mrr >= best_result[1]:\n",
        "        best_result[1] = mrr\n",
        "        best_epoch[1]=epoch\n",
        "    print('train_loss:\\t%.4f\\ttest_loss:\\t%4f\\tRecall@20:\\t%.4f\\tMMR@20:\\t%.4f\\tEpoch:\\t%d,\\t%d'%\n",
        "          (loss, test_loss, best_result[0], best_result[1], best_epoch[0], best_epoch[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGSY4X3aSBnh"
      },
      "outputs": [],
      "source": [
        "train.length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8Vdrqa2H_tS"
      },
      "outputs": [],
      "source": [
        "print(train_data.mask)\n",
        "print(train_data.len_max)\n",
        "\n",
        "print(train_data.inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
